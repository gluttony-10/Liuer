# coding=utf-8

import os
import gradio as gr
import torch
from funasr import AutoModel
from funasr_onnx import SeacoParaformer, CT_Transformer
import gc

os.environ["MODELSCOPE_CACHE"] = ".glut/.modelscope"

class FunASRApp:
    def __init__(self):
        self.model = None
        self.hotwords = self._load_hotwords()


    def _load_hotwords(self):
        try:
            with open("hotwords.txt", "r") as f:
                return f.read().strip()
        except FileNotFoundError:
            return "çƒ­è¯ ç”¨ç©ºæ ¼ éš”å¼€ åå­—é±¼"


    def load_model(
            self, 
            model, 
            vad_model="fsmn-vad", 
            vad_kwargs={"max_single_segment_time": 30000}, 
            punc_model="ct-punc",  
            spk_model="cam++",
            device="cuda",
            disable_update=True,
    ):
        gc.collect()
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()
        if "é€‰æ‹©" in model:
            self.model = None
            print(f'\033[31mè¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹\033[0m')
            return "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹", gr.update(interactive=True)
        elif "æƒ…æ„Ÿ" in model:
            punc_model = None
            spk_model = None
            model_name = "iic/SenseVoiceSmall"
            model = "æƒ…æ„Ÿæ¨¡å‹"
        elif model == "çƒ­è¯æ¨¡å‹":
            model_name = "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
        elif model == "çƒ­è¯æ¨¡å‹onnxç‰ˆ":
            model_name = "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
            model_punc = "iic/punc_ct-transformer_cn-en-common-vocab471067-large"
            self.model = SeacoParaformer(model_name, batch_size=1, quantize=True)
            self.model2 = CT_Transformer(model_punc, batch_size=1, quantize=True)
            print(f'\033[32m{model}åŠ è½½æˆåŠŸ\033[0m')
            return f"{model}åŠ è½½å®Œæˆ", gr.update(interactive=True)
        
        print(f'\033[32må¼€å§‹åŠ è½½{model}\033[0m')
        self.model = AutoModel(
            model=model_name,  
            vad_model=vad_model, 
            vad_kwargs=vad_kwargs,
            punc_model=punc_model, 
            spk_model=spk_model,
            device=device,
            disable_update=disable_update,
        )
        print(f'\033[32m{model}åŠ è½½æˆåŠŸ\033[0m')
        return f"{model}åŠ è½½å®Œæˆ", gr.update(interactive=True)
    

    def model_inference(
            self,
            model,
            video_input,
            language,
            hotwords,
            format_selector,
            save_button,
            use_itn=True,
            batch_size_s=60, 
            merge_vad=True,
            merge_length_s=15,
            sentence_timestamp=True,
    ):        
        gc.collect()
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()

        with open("hotwords.txt", "w") as f:
            f.write(hotwords)

        if "é€‰æ‹©" in model:
            print(f'\033[31mè¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹\033[0m')
            return "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹", "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹"
        elif "æƒ…æ„Ÿ" in model:
            if format_selector in ["LRC", "SRT"]:
                print(f'\033[31mæƒ…æ„Ÿæ¨¡å‹ä»…æ”¯æŒTXTæ ¼å¼\033[0m')
                return "æƒ…æ„Ÿæ¨¡å‹ä»…æ”¯æŒTXTæ ¼å¼", "æƒ…æ„Ÿæ¨¡å‹ä»…æ”¯æŒTXTæ ¼å¼"
            sentence_timestamp = False
            model = "æƒ…æ„Ÿæ¨¡å‹"
        elif model == "çƒ­è¯æ¨¡å‹":
            model = "çƒ­è¯æ¨¡å‹"
        elif model == "çƒ­è¯æ¨¡å‹onnxç‰ˆ":
            for input in video_input:
                asr_result = self.model(
                input,
                hotwords=hotwords
                )
                punc_result = self.model2(asr_result[0]['preds'])
                res = self.merge_asr_and_punc(asr_result, punc_result, input)
                status_text, content = self.process_result(res, input, format_selector, save_button, model)
            return status_text, content

        language_abbr = {"è‡ªåŠ¨": "auto", "ä¸­æ–‡": "zh", "è‹±æ–‡": "en", "ç²¤è¯­": "yue", "æ—¥æ–‡": "ja", "éŸ©æ–‡": "ko", "æ— è¯­è¨€": "nospeech"}
        language = "è‡ªåŠ¨" if len(language) < 1 else language
        language = language_abbr[language]
        
        for input in video_input:
            res = self.model.generate(
                input=input,
                cache={},
                language=language,
                use_itn=use_itn,
                batch_size_s=batch_size_s, 
                merge_vad=merge_vad,
                merge_length_s=merge_length_s,
                sentence_timestamp=sentence_timestamp,
                hotwords=hotwords,
            )
            status_text, content = self.process_result(res, input, format_selector, save_button, model)
        print(res)
        return status_text, content
    

    def merge_asr_and_punc(self, asr_result, punc_result, audio_key):
        # æå– asr_result ä¸­çš„ä¿¡æ¯
        timestamps = asr_result[0]['timestamp']
        
        # æå– punc_result ä¸­çš„ä¿¡æ¯
        original_text = asr_result[0]['preds'].split()
        punctuated_text = punc_result[0]
        
        # æ ¹æ®æ ‡ç‚¹ç¬¦å·åˆ†å‰²æ–‡æœ¬å’Œæ—¶é—´æˆ³
        sentences = []
        sentence_timestamps = []
        start_index = 0
        n = 1
        
        # å®šä¹‰æ ‡ç‚¹ç¬¦å·
        punctuation_marks = "ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š"
        
        for i, char in enumerate(punctuated_text):
            if char in punctuation_marks:
                end_index = i
                sentence = original_text[start_index:end_index-n+1] + [char]
                print(sentence)
                sentence_timestamp = timestamps[start_index:(end_index-n+1)]
                sentences.append(sentence)
                sentence_timestamps.append(sentence_timestamp)
                start_index = end_index-n+1
                n += 1
        
        # å¤„ç†æœ€åä¸€ä¸ªå¥å­ï¼ˆå¦‚æœæ²¡æœ‰ä»¥æ ‡ç‚¹ç¬¦å·ç»“å°¾ï¼‰
        if start_index < len(punctuated_text):
            sentence = punctuated_text[start_index:]
            sentence_timestamp = timestamps[start_index:]
            sentences.append(sentence)
            sentence_timestamps.append(sentence_timestamp)
        
        # æ„å»ºæœ€ç»ˆçš„è¾“å‡ºæ ¼å¼
        sentence_info = []
        
        for sentence, timestamp in zip(sentences, sentence_timestamps):
            if timestamp:  # ç¡®ä¿ timestamp ä¸ä¸ºç©º
                start_time = timestamp[0][0]
                end_time = timestamp[-1][1]
                sentence_info.append({
                    'text': sentence,
                    'start': start_time,
                    'end': end_time,
                    'timestamp': timestamp,
                    'spk': 0
                })
        
        output = [{
            'key': audio_key,
            'text': punctuated_text,
            'timestamp': [ts for sublist in sentence_timestamps for ts in sublist],
            'sentence_info': sentence_info
        }]
        
        return output
    

    def process_result(
            self, 
            res, 
            input, 
            format_selector, 
            save_button, model
    ):
        output_dir = "outputs"
        os.makedirs(output_dir, exist_ok=True)
        filename = os.path.basename(input)
        filename_without_extension, extension = os.path.splitext(filename)
        
        # æ ¹æ®æ ¼å¼ç”Ÿæˆå†…å®¹
        base_path = os.path.join(output_dir, filename_without_extension)
        if format_selector == "LRC":
            content = self._generate_lrc(res)
            if save_button:
                with open(f"{base_path}.lrc", "w") as f:
                    f.write(content)
        elif format_selector == "SRT":
            content = self._generate_srt(res)
            if save_button:
                with open(f"{base_path}.srt", "w") as f:
                    f.write(content)
        else:
            content = res[0]["text"]
            if format_selector:
                with open(f"{base_path}.txt", "w") as f:
                    f.write(content)

        status_text = f"{model}è¯†åˆ«æˆåŠŸ"
        if save_button:
            status_text += f"ï¼Œ{format_selector}æ–‡ä»¶å·²ä¿å­˜è‡³{output_dir}"
        else:
            status_text += "ï¼Œæœªé€‰æ‹©ä¿å­˜æ–‡ä»¶"

        return status_text, content


    def _generate_lrc(self, res):
        """ç”Ÿæˆæ ‡å‡†LRCæ­Œè¯æ ¼å¼"""
        lrc_lines = []
        for segment in res[0]["sentence_info"]:
            start = self._format_lrc_time(segment.get("start", 0.0))
            text = segment.get("text", "")
            # æ·»åŠ ç±»å‹è½¬æ¢
            if isinstance(text, list):
                text = "".join(text)
            text = text.strip()
            # ç®€åŒ–ä¸ºåªæ˜¾ç¤ºå¼€å§‹æ—¶é—´
            lrc_lines.append(f"[{start}]{text}") 
        return "\n".join(lrc_lines)
    

    def _format_lrc_time(self, seconds):
        """LRCæ—¶é—´æ ¼å¼è½¬æ¢ï¼ˆåˆ†:ç§’.å˜ç§’ï¼‰"""
        seconds /= 1000
        total_seconds = round(seconds, 2)  # ç²¾ç¡®åˆ°å˜ç§’
        mins = int(total_seconds // 60)
        secs = total_seconds % 60
        return f"{mins:02d}:{secs:05.2f}"  # ç¤ºä¾‹ï¼š37.28ç§’ â†’ 00:37.28


    def _generate_srt(self, res):
        """ç”Ÿæˆæ ‡å‡†SRTå­—å¹•æ ¼å¼ï¼ˆå¸¦åºå·å’Œæ—¶é—´èŒƒå›´ï¼‰"""
        srt_lines = []
        for index, segment in enumerate(res[0]["sentence_info"], 1):
            # æ—¶é—´æ ¼å¼è½¬æ¢ï¼ˆæ–°å¢å¸¦å°æ—¶çš„ä¸‰æ®µå¼æ ¼å¼ï¼‰
            start = self._format_srt_time(segment.get("start", 0.0))
            end = self._format_srt_time(segment.get("end", 0.0))
            text = segment.get("text", "")
            # æ·»åŠ ç±»å‹è½¬æ¢
            if isinstance(text, list):
                text = "".join(text)
            text = text.strip()
            
            # æ„å»ºå­—å¹•å—
            srt_lines.append(f"{index}")
            srt_lines.append(f"{start} --> {end}")
            srt_lines.append(f"{text}\n")
        
        return "\n".join(srt_lines)
    

    def _format_srt_time(self, seconds):
        seconds /= 1000
        """SRTä¸“ç”¨æ—¶é—´æ ¼å¼è½¬æ¢ï¼ˆå°æ—¶:åˆ†é’Ÿ:ç§’,æ¯«ç§’ï¼‰"""
        hours = int(seconds // 3600)
        remainder = seconds % 3600
        mins = int(remainder // 60)
        secs = remainder % 60
        return f"{hours:02d}:{mins:02d}:{secs:06.3f}".replace('.', ',')


    def launch(self):
        with gr.Blocks(theme=gr.themes.Soft(), fill_height=True) as demo:
            gr.HTML(html_content)
            with gr.Row():
                with gr.Column():
                    video_input = gr.File(
                        label="ä¸Šä¼ éŸ³è§†é¢‘æ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰", 
                        file_count="multiple",
                        file_types=["video","audio"],
                        type="filepath"
                    )                           
                    with gr.Accordion(label="é…ç½®"):
                        model_inputs = gr.Dropdown(
                            label="æ¨¡å‹", 
                            choices=["çƒ­è¯æ¨¡å‹", "çƒ­è¯æ¨¡å‹onnxç‰ˆ", "æƒ…æ„Ÿæ¨¡å‹", "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹"], 
                            value="è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹"
                        )
                        language_inputs = gr.Dropdown(
                            label="è¯­è¨€", 
                            choices=["è‡ªåŠ¨", "ä¸­æ–‡", "è‹±æ–‡", "ç²¤è¯­", "æ—¥æ–‡", "éŸ©æ–‡", "æ— è¯­è¨€"], 
                            value="è‡ªåŠ¨"
                        )
                        format_selector = gr.Dropdown(
                            label="æ ¼å¼",
                            choices=["TXT", "LRC", "SRT"],
                            value="TXT"
                        )
                        save_button = gr.Checkbox(label="ä¿å­˜æ–‡ä»¶", value=False)
                        hotwords_inputs = gr.Textbox(label="çƒ­è¯", value=self.hotwords)
                    fn_button = gr.Button("å¼€å§‹", variant="primary")
                with gr.Column():
                    status_text = gr.Textbox(label="çŠ¶æ€", value="è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹", interactive=False)
                    text_outputs = gr.Textbox(label="è¾“å‡º")
            model_inputs.change(
                self.load_model, 
                inputs=model_inputs, 
                outputs=[status_text, model_inputs]
            )
            fn_button.click(
                self.model_inference, 
                inputs=[
                    model_inputs,
                    video_input,
                    language_inputs, 
                    hotwords_inputs,
                    format_selector,
                    save_button
                ],
                outputs=[status_text, text_outputs],
                queue=True,
                show_progress=True
            )
        demo.launch(inbrowser=True, share=False, server_name="127.0.0.1")

html_content = """
<div>
    <h2 style="font-size: 22px;text-align: center;">è¯­éŸ³è¯†åˆ« å­—å¹•åˆ¶ä½œ</h2>
</div>
<div style="text-align: center; font-size: 15px; font-weight: bold; color: red;">
    âš ï¸ è¯¥æ¼”ç¤ºä»…ä¾›å­¦æœ¯ç ”ç©¶å’Œä½“éªŒä½¿ç”¨ã€‚
</div>
<div style="text-align: center;">
    åˆ¶ä½œ by åå­—é±¼|
    <a href="https://space.bilibili.com/893892">ğŸŒ bilibili</a> 
</div>
"""

if __name__ == "__main__":
    total_vram_in_gb = torch.cuda.get_device_properties(0).total_memory / 1073741824
    print("å¼€æºé¡¹ç›®ï¼šhttps://github.com/gluttony-10/FunASR-webui bilibili@åå­—é±¼ https://space.bilibili.com/893892 ")
    print(f'\033[32mCUDAç‰ˆæœ¬ï¼š{torch.version.cuda}\033[0m')
    print(f'\033[32mPytorchç‰ˆæœ¬ï¼š{torch.__version__}\033[0m')
    print(f'\033[32mæ˜¾å¡å‹å·ï¼š{torch.cuda.get_device_name()}\033[0m')
    print(f'\033[32mæ˜¾å­˜å¤§å°ï¼š{total_vram_in_gb:.2f}GB\033[0m')
    if torch.cuda.get_device_capability()[0] >= 8:
        print(f'\033[32mæ”¯æŒBF16\033[0m')
        dtype = torch.bfloat16
    else:
        print(f'\033[32mä¸æ”¯æŒBF16ï¼Œä½¿ç”¨FP16\033[0m')
        dtype = torch.float16
    app = FunASRApp()
    app.launch()