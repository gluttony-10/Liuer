# coding=utf-8

import os
import gradio as gr
import numpy as np
import torch
import torchaudio
from funasr import AutoModel
import gc
import json
from pathlib import Path

class FunASRApp:
    def __init__(self):
        self.model = None
        self.hotword = self._load_hotwords()


    def _load_hotwords(self):
        try:
            with open("hotwords.txt", "r") as f:
                return f.read().strip()
        except FileNotFoundError:
            return "çƒ­è¯ ç”¨ç©ºæ ¼ éš”å¼€ åå­—é±¼"


    def load_model(
            self, 
            model, 
            vad_model="fsmn-vad", 
            vad_kwargs={"max_single_segment_time": 30000}, 
            punc_model="ct-punc",  
            spk_model="cam++",
            device="cuda",
            disable_update=True,
    ):
        gc.collect()
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()
        if "é€‰æ‹©" in model:
            self.model = None
            print(f'\033[31mè¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹\033[0m')
            return "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹", gr.update(interactive=True)
        elif "æƒ…æ„Ÿ" in model:
            punc_model = None
            spk_model = None
            model_name = "iic/SenseVoiceSmall"
            model = "æƒ…æ„Ÿæ¨¡å‹"
        elif "çƒ­è¯" in model:
            model_name = "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
            model = "çƒ­è¯æ¨¡å‹"
        print(f'\033[32må¼€å§‹åŠ è½½{model}\033[0m')
        self.model = AutoModel(
            model=model_name,  
            vad_model=vad_model, 
            vad_kwargs=vad_kwargs,
            punc_model=punc_model, 
            spk_model=spk_model,
            device=device,
            disable_update=disable_update,
        )
        print(f'\033[32m{model}åŠ è½½æˆåŠŸ\033[0m')
        return f"{model}åŠ è½½å®Œæˆ", gr.update(interactive=True)
    

    def model_inference(
            self,
            model,
            video_input,
            language,
            hotword,
            format_selector,
            save_button,
            use_itn=True,
            batch_size_s=60, 
            merge_vad=True,
            merge_length_s=15,
            sentence_timestamp=True,
    ):        
        if "é€‰æ‹©" in model:
            print(f'\033[31mè¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹\033[0m')
            return "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹", "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹"
        elif "æƒ…æ„Ÿ" in model:
            if format_selector in ["LRC", "SRC"]:
                print(f'\033[31mæƒ…æ„Ÿæ¨¡å‹ä»…æ”¯æŒTXTæ ¼å¼\033[0m')
                return "æƒ…æ„Ÿæ¨¡å‹ä»…æ”¯æŒTXTæ ¼å¼", "æƒ…æ„Ÿæ¨¡å‹ä»…æ”¯æŒTXTæ ¼å¼"
            sentence_timestamp = False
            model = "æƒ…æ„Ÿæ¨¡å‹"
        elif "çƒ­è¯" in model:
            model = "çƒ­è¯æ¨¡å‹"
        
        with open("hotwords.txt", "w") as f:
            f.write(hotword)

        gc.collect()
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()
        language_abbr = {"è‡ªåŠ¨": "auto", "ä¸­æ–‡": "zh", "è‹±æ–‡": "en", "ç²¤è¯­": "yue", "æ—¥æ–‡": "ja", "éŸ©æ–‡": "ko", "æ— è¯­è¨€": "nospeech"}
        language = "è‡ªåŠ¨" if len(language) < 1 else language
        language = language_abbr[language]
        
        for input in video_input:
            res = self.model.generate(
                input=input,
                cache={},
                language=language,
                use_itn=use_itn,
                batch_size_s=batch_size_s, 
                merge_vad=merge_vad,
                merge_length_s=merge_length_s,
                sentence_timestamp=sentence_timestamp,
                hotword=hotword,
            )
            #print(res) # è¾“å‡ºåŸå§‹è¯†åˆ«ç»“æœ

            output_dir = "outputs"
            os.makedirs(output_dir, exist_ok=True)
            filename = os.path.basename(input)
            filename_without_extension, extension = os.path.splitext(filename)
            
            # æ ¹æ®æ ¼å¼ç”Ÿæˆå†…å®¹
            base_path = os.path.join(output_dir, filename_without_extension)
            if format_selector == "LRC":
                content = self._generate_lrc(res)
                if save_button:
                    with open(f"{base_path}.lrc", "w") as f:
                        f.write(content)
            elif format_selector == "SRC":
                content = self._generate_src(res)
                if save_button:
                    with open(f"{base_path}.src", "w") as f:
                        f.write(content)
            else:
                content = res[0]["text"]
                if format_selector:
                    with open(f"{base_path}.txt", "w") as f:
                        f.write(content)

            status_text = f"{model}è¯†åˆ«æˆåŠŸ"
            if save_button:
                status_text += f"ï¼Œ{format_selector}æ–‡ä»¶å·²ä¿å­˜è‡³{output_dir}"
            else:
                status_text += "ï¼Œæœªé€‰æ‹©ä¿å­˜æ–‡ä»¶"
        
        return status_text, content


    def _generate_lrc(self, res):
        """ç”Ÿæˆæ ‡å‡†LRCæ­Œè¯æ ¼å¼"""
        lrc_lines = []
        for segment in res[0]["sentence_info"]:
            start = self._format_lrc_time(segment.get("start", 0.0))
            text = segment.get("text", "").strip()
            # ç®€åŒ–ä¸ºåªæ˜¾ç¤ºå¼€å§‹æ—¶é—´
            lrc_lines.append(f"[{start}]{text}") 
        return "\n".join(lrc_lines)
    

    def _format_lrc_time(self, seconds):
        """LRCæ—¶é—´æ ¼å¼è½¬æ¢ï¼ˆåˆ†:ç§’.å˜ç§’ï¼‰"""
        seconds /= 1000
        total_seconds = round(seconds, 2)  # ç²¾ç¡®åˆ°å˜ç§’
        mins = int(total_seconds // 60)
        secs = total_seconds % 60
        return f"{mins:02d}:{secs:05.2f}"  # ç¤ºä¾‹ï¼š37.28ç§’ â†’ 00:37.28


    def _generate_src(self, res):
        """ç”Ÿæˆæ ‡å‡†SRCå­—å¹•æ ¼å¼ï¼ˆå¸¦åºå·å’Œæ—¶é—´èŒƒå›´ï¼‰"""
        src_lines = []
        for index, segment in enumerate(res[0]["sentence_info"], 1):
            # æ—¶é—´æ ¼å¼è½¬æ¢ï¼ˆæ–°å¢å¸¦å°æ—¶çš„ä¸‰æ®µå¼æ ¼å¼ï¼‰
            start = self._format_src_time(segment.get("start", 0.0))
            end = self._format_src_time(segment.get("end", 0.0))
            text = segment.get("text", "").strip()
            
            # æ„å»ºå­—å¹•å—
            src_lines.append(f"{index}")
            src_lines.append(f"{start} --> {end}")
            src_lines.append(f"{text}\n")
        
        return "\n".join(src_lines)
    

    def _format_src_time(self, seconds):
        seconds /= 1000
        """SRCä¸“ç”¨æ—¶é—´æ ¼å¼è½¬æ¢ï¼ˆå°æ—¶:åˆ†é’Ÿ:ç§’,æ¯«ç§’ï¼‰"""
        hours = int(seconds // 3600)
        remainder = seconds % 3600
        mins = int(remainder // 60)
        secs = remainder % 60
        return f"{hours:02d}:{mins:02d}:{secs:06.3f}".replace('.', ',')


    def launch(self):
        with gr.Blocks(theme=gr.themes.Soft(), fill_height=True) as demo:
            gr.HTML(html_content)
            with gr.Row():
                with gr.Column():
                    video_input = gr.File(
                        label="ä¸Šä¼ éŸ³è§†é¢‘æ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰", 
                        file_count="multiple",
                        file_types=["video","audio"],
                        type="filepath"
                    )                           
                    with gr.Accordion(label="é…ç½®"):
                        model_inputs = gr.Dropdown(
                            label="æ¨¡å‹", 
                            choices=["çƒ­è¯æ¨¡å‹", "æƒ…æ„Ÿæ¨¡å‹", "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹"], 
                            value="è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹"
                        )
                        language_inputs = gr.Dropdown(
                            label="è¯­è¨€", 
                            choices=["è‡ªåŠ¨", "ä¸­æ–‡", "è‹±æ–‡", "ç²¤è¯­", "æ—¥æ–‡", "éŸ©æ–‡", "æ— è¯­è¨€"], 
                            value="è‡ªåŠ¨"
                        )
                        format_selector = gr.Dropdown(
                            label="æ ¼å¼",
                            choices=["TXT", "LRC", "SRC"],
                            value="TXT"
                        )
                        save_button = gr.Checkbox(label="ä¿å­˜æ–‡ä»¶", value=False)
                        hotword_inputs = gr.Textbox(label="çƒ­è¯", value=self.hotword)
                    fn_button = gr.Button("å¼€å§‹", variant="primary")
                with gr.Column():
                    status_text = gr.Textbox(label="çŠ¶æ€", value="è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹", interactive=False)
                    text_outputs = gr.Textbox(label="è¾“å‡º")
            model_inputs.change(
                self.load_model, 
                inputs=model_inputs, 
                outputs=[status_text, model_inputs]
            )
            fn_button.click(
                self.model_inference, 
                inputs=[
                    model_inputs,
                    video_input,
                    language_inputs, 
                    hotword_inputs,
                    format_selector,
                    save_button
                ],
                outputs=[status_text, text_outputs],
                queue=True,
                show_progress=True
            )
        demo.launch(inbrowser=True, share=False, server_name="127.0.0.1")

html_content = """
<div>
    <h2 style="font-size: 22px;text-align: center;">è¯­éŸ³è¯†åˆ« å­—å¹•åˆ¶ä½œ</h2>
</div>
<div style="text-align: center; font-size: 15px; font-weight: bold; color: red;">
    âš ï¸ è¯¥æ¼”ç¤ºä»…ä¾›å­¦æœ¯ç ”ç©¶å’Œä½“éªŒä½¿ç”¨ã€‚
</div>
<div style="text-align: center;">
    åˆ¶ä½œ by åå­—é±¼|
    <a href="https://space.bilibili.com/893892">ğŸŒ bilibili</a> 
</div>
"""

if __name__ == "__main__":
    total_vram_in_gb = torch.cuda.get_device_properties(0).total_memory / 1073741824
    print("å¼€æºé¡¹ç›®ï¼šhttps://github.com/gluttony-10/FunASR-webui bilibili@åå­—é±¼ https://space.bilibili.com/893892 ")
    print(f'\033[32mCUDAç‰ˆæœ¬ï¼š{torch.version.cuda}\033[0m')
    print(f'\033[32mPytorchç‰ˆæœ¬ï¼š{torch.__version__}\033[0m')
    print(f'\033[32mæ˜¾å¡å‹å·ï¼š{torch.cuda.get_device_name()}\033[0m')
    print(f'\033[32mæ˜¾å­˜å¤§å°ï¼š{total_vram_in_gb:.2f}GB\033[0m')
    if torch.cuda.get_device_capability()[0] >= 8:
        print(f'\033[32mæ”¯æŒBF16\033[0m')
        dtype = torch.bfloat16
    else:
        print(f'\033[32mä¸æ”¯æŒBF16ï¼Œä½¿ç”¨FP16\033[0m')
        dtype = torch.float16
    app = FunASRApp()
    app.launch()