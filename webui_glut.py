# coding=utf-8

import os
import gradio as gr
import numpy as np
import torch
import torchaudio
from funasr import AutoModel
import gc

class FunASRApp:
    def __init__(self):
        self.model = None


    def load_model(
            self, 
            model, 
            vad_model="fsmn-vad", 
            vad_kwargs={"max_single_segment_time": 30000}, 
            punc_model="ct-punc",  
            spk_model="cam++",
            device="cuda:0",
            disable_update=True,
    ):
        gc.collect()
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()
        if model == "ç©ºè½½æ¨¡å‹":
            self.model = None
            print("æ¨¡å‹å·²å¸è½½")
            return "æ¨¡å‹å·²å¸è½½", gr.update(interactive=True)
        elif model == "æƒ…æ„Ÿæ¨¡å‹":
            punc_model = None
            spk_model = None
        
        print(f"å¼€å§‹åŠ è½½{model}")
        model_abbr = {"çƒ­è¯æ¨¡å‹": "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch", "æƒ…æ„Ÿæ¨¡å‹": "iic/SenseVoiceSmall"}        
        model = model_abbr[model]
        self.model = AutoModel(
            model=model,  
            vad_model=vad_model, 
            vad_kwargs=vad_kwargs,
            punc_model=punc_model, 
            spk_model=spk_model,
            device=device,
            disable_update=disable_update,
        )
        print(f"åŠ è½½{model}æˆåŠŸ")
        return "æ¨¡å‹åŠ è½½å®Œæˆ", gr.update(interactive=True)


    def model_inference(
            self, 
            model,
            input, 
            language, 
            hotword='glut',
            use_itn=True,
            batch_size_s=60, 
            merge_vad=True,
            merge_length_s=15,
            sentence_timestamp=True,
            fs=16000
    ):
        if self.model is None:
            return "è¯·å…ˆé€‰æ‹©å¹¶åŠ è½½æ¨¡å‹"
        if model == "æƒ…æ„Ÿæ¨¡å‹":
            sentence_timestamp = False
        
        gc.collect()
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()
        language_abbr = {"è‡ªåŠ¨": "auto", "ä¸­æ–‡": "zh", "è‹±æ–‡": "en", "ç²¤è¯­": "yue", "æ—¥æ–‡": "ja", "éŸ©æ–‡": "ko", "æ— è¯­è¨€": "nospeech"}
        language = "è‡ªåŠ¨" if len(language) < 1 else language
        language = language_abbr[language]

        if isinstance(input, tuple):
            fs, input = input
            input = input.astype(np.float32) / np.iinfo(np.int16).max
            if len(input.shape) > 1:
                input = input.mean(-1)
            if fs != 16000:
                print(f"audio_fs: {fs}")
                resampler = torchaudio.transforms.Resample(fs, 16000)
                input_t = torch.from_numpy(input).to(torch.float32)
                input = resampler(input_t[None, :])[0, :].numpy()
        
        res = self.model.generate(
            input=input,
            cache={},
            language=language,
            use_itn=use_itn,
            batch_size_s=batch_size_s, 
            merge_vad=merge_vad,
            merge_length_s=merge_length_s,
            sentence_timestamp=sentence_timestamp,
            hotword=hotword,
        )
        print(res)
        text = res[0]["text"]
        return res, text


    def save_txt(self, text):
        save_path = os.path.join("outputs", "text_files", "output.txt")
        with open(save_path, "w") as f:
            f.write(text)
        return "Text saved to " + save_path


    def launch(self):
        with gr.Blocks(theme=gr.themes.Soft(), fill_height=True) as demo:
            gr.HTML(html_content)
            with gr.Row():
                with gr.Column():
                    audio_inputs = gr.Audio(label="ä¸Šä¼ éŸ³é¢‘æˆ–ä½¿ç”¨éº¦å…‹é£", format="wav", editable=True)
                    with gr.Accordion(label="é…ç½®"):
                        model_inputs = gr.Dropdown(label="æ¨¡å‹", choices=["çƒ­è¯æ¨¡å‹", "æƒ…æ„Ÿæ¨¡å‹", "ç©ºè½½æ¨¡å‹"], value="ç©ºè½½æ¨¡å‹")
                        status_text = gr.Textbox(label="æ¨¡å‹çŠ¶æ€", value="æ¨¡å‹æœªåŠ è½½", interactive=False, visible=False)
                        language_inputs = gr.Dropdown(label="è¯­è¨€", choices=["è‡ªåŠ¨", "ä¸­æ–‡", "è‹±æ–‡", "ç²¤è¯­", "æ—¥æ–‡", "éŸ©æ–‡", "æ— è¯­è¨€"], value="è‡ªåŠ¨")
                        hotword_inputs = gr.Textbox(label="çƒ­è¯", value="çƒ­è¯ ç”¨ç©ºæ ¼ éš”å¼€ åå­—é±¼")
                    fn_button = gr.Button("å¼€å§‹", variant="primary")
                with gr.Column():
                    res_outputs = gr.Textbox(label="ç»“æœ", visible=False)
                    text_outputs = gr.Textbox(label="ç»“æœ")
            model_inputs.change(self.load_model, inputs=model_inputs, outputs=[status_text, model_inputs])
            fn_button.click(self.model_inference, inputs=[model_inputs, audio_inputs, language_inputs, hotword_inputs], outputs=[res_outputs, text_outputs])

        demo.launch(inbrowser=True, share=False)

html_content = """
<div>
    <h2 style="font-size: 22px;text-align: center;">FunASRåº”ç”¨ç¨‹åº FunASR-webui</h2>
</div>
<div style="text-align: center; font-size: 15px; font-weight: bold; color: red;">
    âš ï¸ è¯¥æ¼”ç¤ºä»…ä¾›å­¦æœ¯ç ”ç©¶å’Œä½“éªŒä½¿ç”¨ã€‚
</div>
<div style="text-align: center;">
    åˆ¶ä½œ by åå­—é±¼|
    <a href="https://space.bilibili.com/893892">ğŸŒ Bilibili</a> 
</div>
"""

if __name__ == "__main__":
    app = FunASRApp()
    app.launch()