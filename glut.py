# coding=utf-8

import os
import gradio as gr
import torch
from funasr import AutoModel
import gc
import whisper
import subprocess
import re
import glob
from datetime import datetime
from openai import OpenAI


PYTHON = os.environ.get("PYTHON", "python")
YTDLP = os.environ.get("YTDLP", "yt-dlp")
MODEL_NAME = os.environ.get("MODEL_NAME", "glm-4-flash")

class FunASRApp:
    def __init__(self):
        self.model = None
        self.hotwords = self._load_hotwords()


    def _load_hotwords(self):
        try:
            with open("hotwords.txt", "r", encoding="utf-8") as f:
                return f.read().strip()
        except FileNotFoundError:
            return "çƒ­è¯ ç”¨ç©ºæ ¼ éš”å¼€ åå­—é±¼"


    def load_model(
            self, 
            model, 
            vad_model="fsmn-vad", 
            vad_kwargs={"max_single_segment_time": 30000}, 
            punc_model="ct-punc",  
            spk_model="cam++",
            disable_update=True,
    ):
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
        if "é€‰æ‹©" in model:
            self.model = None
            print(f'\033[31mè¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹\033[0m')
            return "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹", gr.update(interactive=True)
        elif model == "æƒ…æ„Ÿæ¨¡å‹":
            punc_model = None
            spk_model = None
            model_name = "iic/SenseVoiceSmall"
        elif model == "çƒ­è¯æ¨¡å‹":
            model_name = "iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"
        elif model == "æƒ…æ„Ÿæ¨¡å‹ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰":
            self.model = AutoModel(
                model= "iic/SenseVoiceSmall", 
                vad_model=vad_model, 
                vad_kwargs=vad_kwargs,
                disable_update=disable_update,
                device="cuda" if torch.cuda.is_available() else "cpu",
            )
            self.model2 = AutoModel(
                model="fsmn-vad", 
                max_end_silence_time=200, 
                disable_update=disable_update, 
                device="cuda" if torch.cuda.is_available() else "cpu"
            )
            print(f'\033[32m{model}åŠ è½½æˆåŠŸ\033[0m')
            return f"{model}åŠ è½½å®Œæˆ", gr.update(interactive=True)
        elif model == "whisper-large-v3-turbo":
            self.model = whisper.load_model("turbo", download_root="models", device="cuda" if torch.cuda.is_available() else "cpu")
            print(f'\033[32m{model}åŠ è½½æˆåŠŸ\033[0m')
            return f"{model}åŠ è½½å®Œæˆ", gr.update(interactive=True)
        elif model == "whisper-large-v3":
            self.model = whisper.load_model("large", download_root="models", device="cuda" if torch.cuda.is_available() else "cpu")
            print(f'\033[32m{model}åŠ è½½æˆåŠŸ\033[0m')
            return f"{model}åŠ è½½å®Œæˆ", gr.update(interactive=True)
        
        print(f'\033[32må¼€å§‹åŠ è½½{model}\033[0m')
        self.model = AutoModel(
            model=model_name,  
            vad_model=vad_model, 
            vad_kwargs=vad_kwargs,
            punc_model=punc_model, 
            spk_model=spk_model,
            disable_update=disable_update,
            device="cuda" if torch.cuda.is_available() else "cpu",
        )
        print(f'\033[32m{model}åŠ è½½æˆåŠŸ\033[0m')
        return f"{model}åŠ è½½å®Œæˆ", gr.update(interactive=True)
    

    def model_inference(
            self,
            model,
            video_input,
            url_input,
            language,
            language_translation,
            hotwords,
            format_selector,
            speaker,
            use_itn=True,
            batch_size_s=60, 
            merge_vad=True,
            merge_length_s=15,
            sentence_timestamp=True,
    ):        
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
        output_path=[]

        with open("hotwords.txt", "w", encoding="utf-8") as f:
            f.write(hotwords)

        if not video_input and not url_input:
            return "è¯·ä¸Šä¼ æ–‡ä»¶æˆ–è¾“å…¥URL", "è¯·ä¸Šä¼ æ–‡ä»¶æˆ–è¾“å…¥URL", None
        elif url_input:
            urls = [url.strip() for url in url_input.split('\n') if url.strip()]
            downloaded_files = self.download_urls(urls, timestamp)
            video_input = (video_input or []) + downloaded_files
        if speaker==True and model != "çƒ­è¯æ¨¡å‹":
            print(f'\033[31mè¯†åˆ«è¯´è¯äººè¯·é€‰æ‹©çƒ­è¯æ¨¡å‹\033[0m')
            return "è¯†åˆ«è¯´è¯äººè¯·é€‰æ‹©çƒ­è¯æ¨¡å‹", "è¯†åˆ«è¯´è¯äººè¯·é€‰æ‹©çƒ­è¯æ¨¡å‹", None
        if "é€‰æ‹©" in model:
            print(f'\033[31mè¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹\033[0m')
            return "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹", "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹", None
        elif model == "æƒ…æ„Ÿæ¨¡å‹":
            if format_selector in ["LRC", "SRT"]:
                print(f'\033[31mæƒ…æ„Ÿæ¨¡å‹ä»…æ”¯æŒTXTæ ¼å¼\033[0m')
                return "æƒ…æ„Ÿæ¨¡å‹ä»…æ”¯æŒTXTæ ¼å¼", "æƒ…æ„Ÿæ¨¡å‹ä»…æ”¯æŒTXTæ ¼å¼", None
            sentence_timestamp = False
        elif model == "çƒ­è¯æ¨¡å‹":
            model = "çƒ­è¯æ¨¡å‹"
        elif model == "æƒ…æ„Ÿæ¨¡å‹ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰":
            for input in video_input:
                try:
                    res = self.model2.generate(input)
                    full_text = ""
                    sentence_info = []
                    for i, value in enumerate(res[0]['value']):
                        start = value[0]/1000
                        end = value[1]/1000
                        filename = os.path.basename(input)
                        filename_without_extension, extension = os.path.splitext(filename)
                        # FFmpegå‘½ä»¤å‚æ•°
                        os.makedirs("temp", exist_ok=True)
                        temp_path = os.path.join("temp", f"{filename_without_extension}_{i:04d}_{start:.2f}-{end:.2f}{extension}")
                        cmd = [
                            'ffmpeg',
                            '-y',  # è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶
                            '-ss', str(start),   # å¼€å§‹æ—¶é—´
                            '-to', str(end),     # ç»“æŸæ—¶é—´
                            '-i', input,    # è¾“å…¥æ–‡ä»¶
                            '-c', 'copy',        # æµå¤åˆ¶ï¼ˆæ— æŸå¿«é€Ÿï¼‰
                            temp_path
                        ]
                        # æ‰§è¡Œå‘½ä»¤
                        try:
                            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
                            asr_result = self.model.generate(input=temp_path)
                            cleaned_text = re.sub(r'<[^>]+>', '', asr_result[0]["text"])
                            full_text += " " + cleaned_text
                            sentence_info.append({
                                "text": cleaned_text,
                                "start": start * 1000,
                                "end": end * 1000
                            })
                        except subprocess.CalledProcessError as e:
                            print(f"\033[31måˆ†å‰²å¤±è´¥ï¼š{e.stderr.decode()}\033[0m")
                        finally:
                            # æ–°å¢æ¸…ç†ä»£ç 
                            if os.path.exists(temp_path):
                                try:
                                    os.remove(temp_path)
                                except Exception as e:
                                    print(f"\033[31mæ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}\033[0m")
                    res[0].update({
                        "text": full_text.strip(),
                        "sentence_info": sentence_info
                    })
                    #print(res) # åŸå§‹è¾“å‡º
                    status_text, content, output_file = self.process_result(res, model, input, language_translation, format_selector, speaker, timestamp)
                    output_path.append(output_file)
                    yield status_text, content, gr.update(value=output_path, visible=True)
                except Exception as e:
                    print(f"\033[31mæ£€æµ‹æŠ¥é”™ï¼š{str(e)}\033[0m")
                    continue
            return status_text, content, gr.update(value=output_path, visible=True)
        elif "whisper" in model:
            language_abbr = {"è‡ªåŠ¨": None, "ä¸­æ–‡": "zh", "è‹±æ–‡": "en", "ç²¤è¯­": "yue", "æ—¥æ–‡": "ja", "éŸ©æ–‡": "ko", "æ— è¯­è¨€": "nospeech"}
            language = "è‡ªåŠ¨" if len(language) < 1 else language
            language = language_abbr[language]
            for input in video_input:
                try:
                    res = self.model.transcribe(input, no_speech_threshold=0.5, logprob_threshold=None, compression_ratio_threshold=2.2, language=language)
                    res["sentence_info"] = res.pop("segments")
                    for segment in res["sentence_info"]:
                        segment["start"] *= 1000  # ç§’ -> æ¯«ç§’
                        segment["end"] *= 1000    # ç§’ -> æ¯«ç§’
                    res = [res]
                    #print(res) # åŸå§‹è¾“å‡º
                    status_text, content, output_file = self.process_result(res, model, input, language_translation, format_selector, speaker, timestamp)
                    output_path.append(output_file)
                    yield status_text, content, gr.update(value=output_path, visible=True)
                except Exception as e:
                    print(f"\033[31mæ£€æµ‹æŠ¥é”™ï¼š{str(e)}\033[0m")
                    continue
            return status_text, content, gr.update(value=output_path, visible=True)

        language_abbr = {"è‡ªåŠ¨": "auto", "ä¸­æ–‡": "zh", "è‹±æ–‡": "en", "ç²¤è¯­": "yue", "æ—¥æ–‡": "ja", "éŸ©æ–‡": "ko", "æ— è¯­è¨€": "nospeech"}
        language = "è‡ªåŠ¨" if len(language) < 1 else language
        language = language_abbr[language]
        
        for input in video_input:
            try:
                res = self.model.generate(
                    input=input,
                    cache={},
                    language=language,
                    use_itn=use_itn,
                    batch_size_s=batch_size_s, 
                    merge_vad=merge_vad,
                    merge_length_s=merge_length_s,
                    sentence_timestamp=sentence_timestamp,
                    hotword=hotwords,
                )
                status_text, content, output_file = self.process_result(res, model, input, language_translation, format_selector, speaker, timestamp)
                output_path.append(output_file)
                #print(res) # åŸå§‹è¾“å‡º
                yield status_text, content, gr.update(value=output_path, visible=True)
            except Exception as e:
                    print(f"\033[31mæ£€æµ‹æŠ¥é”™ï¼š{str(e)}\033[0m")
                    continue
    

    def process_result(
        self, 
        res, 
        model, 
        input, 
        language_translation,
        format_selector, 
        speaker,
        timestamp,
    ):
        output_dir = f"outputs/{timestamp}"
        os.makedirs(output_dir, exist_ok=True)
        filename = os.path.basename(input)
        filename_without_extension, extension = os.path.splitext(filename)
        
        # æ ¹æ®æ ¼å¼ç”Ÿæˆå†…å®¹
        base_path = os.path.join(output_dir, filename_without_extension)
        if format_selector == "LRC":
            output_file = f"{base_path}.lrc"
            content = self._generate_lrc(res, language_translation, speaker)
        elif format_selector == "SRT":
            output_file = f"{base_path}.srt"
            content = self._generate_srt(res, language_translation, speaker)
        else:
            output_file = f"{base_path}.txt"
            if speaker:
                content = ""
                for i in res[0]["sentence_info"]:
                    content += f"è¯´è¯äºº{i['spk']}ï¼š{i['text']}\n"
            else:
                content = res[0]["text"]
            # ç¿»è¯‘
            content = self.language_translation(content, language_translation)
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(content)
        status_text = f"{model}è¯†åˆ«æˆåŠŸ"
        status_text += f"ï¼Œ{format_selector}æ–‡ä»¶å·²ä¿å­˜è‡³{output_dir}"

        return status_text, content, output_file


    def _generate_lrc(self, res, language_translation, speaker):
        """ç”Ÿæˆæ ‡å‡†LRCæ­Œè¯æ ¼å¼"""
        lrc_lines = []
        for segment in res[0]["sentence_info"]:
            start = self._format_lrc_time(segment.get("start", 0.0))
            if speaker:
                text = f"è¯´è¯äºº{segment['spk']}ï¼š{segment['text']}"
            else:
                text = segment.get("text", "")
            # æ·»åŠ ç±»å‹è½¬æ¢
            if isinstance(text, list):
                text = "".join(text)
            text = text.strip()
            # ç¿»è¯‘
            text = self.language_translation(text, language_translation)
            # ç®€åŒ–ä¸ºåªæ˜¾ç¤ºå¼€å§‹æ—¶é—´
            lrc_lines.append(f"[{start}]{text}") 
        return "\n".join(lrc_lines)
    

    def _format_lrc_time(self, seconds):
        """LRCæ—¶é—´æ ¼å¼è½¬æ¢ï¼ˆåˆ†:ç§’.å˜ç§’ï¼‰"""
        seconds /= 1000
        total_seconds = round(seconds, 2)  # ç²¾ç¡®åˆ°å˜ç§’
        mins = int(total_seconds // 60)
        secs = total_seconds % 60
        return f"{mins:02d}:{secs:05.2f}"  # ç¤ºä¾‹ï¼š37.28ç§’ â†’ 00:37.28


    def _generate_srt(self, res, language_translation, speaker):
        """ç”Ÿæˆæ ‡å‡†SRTå­—å¹•æ ¼å¼ï¼ˆå¸¦åºå·å’Œæ—¶é—´èŒƒå›´ï¼‰"""
        srt_lines = []
        for index, segment in enumerate(res[0]["sentence_info"], 1):
            # æ—¶é—´æ ¼å¼è½¬æ¢ï¼ˆæ–°å¢å¸¦å°æ—¶çš„ä¸‰æ®µå¼æ ¼å¼ï¼‰
            start = self._format_srt_time(segment.get("start", 0.0))
            end = self._format_srt_time(segment.get("end", 0.0))
            if speaker:
                text = f"è¯´è¯äºº{segment['spk']}ï¼š{segment['text']}"
            else:
                text = segment.get("text", "")
            # æ·»åŠ ç±»å‹è½¬æ¢
            if isinstance(text, list):
                text = "".join(text)
            text = text.strip()
            # ç¿»è¯‘
            text =self.language_translation(text, language_translation)
            # æ„å»ºå­—å¹•å—
            srt_lines.append(f"{index}")
            srt_lines.append(f"{start} --> {end}")
            srt_lines.append(f"{text}\n")
        
        return "\n".join(srt_lines)
    

    def _format_srt_time(self, seconds):
        seconds /= 1000
        """SRTä¸“ç”¨æ—¶é—´æ ¼å¼è½¬æ¢ï¼ˆå°æ—¶:åˆ†é’Ÿ:ç§’,æ¯«ç§’ï¼‰"""
        hours = int(seconds // 3600)
        remainder = seconds % 3600
        mins = int(remainder // 60)
        secs = remainder % 60
        return f"{hours:02d}:{mins:02d}:{secs:06.3f}".replace('.', ',')


    def download_urls(self, urls, timestamp):
        downloaded_files = []
        for url in urls:
            if not url.startswith(('http://', 'https://')):
                continue
                
            os.makedirs(f"outputs/{timestamp}", exist_ok=True)
            cmd = [
                PYTHON,
                YTDLP,
                "--quiet",
                "-P", f"outputs/{timestamp}",
                url
            ]
            try:
                subprocess.run(cmd, check=True)
                latest_file = max(
                    glob.glob(f"outputs/{timestamp}/*"), 
                    key=os.path.getctime,
                    default=None
                )
                if latest_file:
                    downloaded_files.append(latest_file)
            except Exception as e:
                print(f"\033[31mä¸‹è½½å¤±è´¥ï¼š{str(e)}\033[0m")
                continue
        return downloaded_files


    def language_translation(self, text: str, language_translation: str, retry_times: int = 3) -> str:
        if not os.environ.get("OPENAI_API_KEY"):
            return text
        if language_translation == "ä¸ç¿»è¯‘":
            return text
        client = OpenAI()
        text = text.strip()

        for i in range(retry_times):
            response = client.chat.completions.create(
                messages=[{"role": "system", "content": """
                    ä½ æ˜¯ä¸€ä½è¯­è¨€ä¸“å®¶ï¼Œç²¾é€šå„å›½è¯­è¨€ã€‚è¯·æŒ‰ç…§è¦æ±‚å¯¹ç”¨æˆ·è¾“å…¥è¿›è¡Œç¿»è¯‘ï¼Œè¦åšåˆ°è¯­å¥ç®€å•ã€ä¿¡è¾¾é›…ã€‚åªè¾“å‡ºç¿»è¯‘å†…å®¹ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚
                """
                },
                {
                    "role": "user",
                    "content":  f'è¯·ç¿»è¯‘æˆ{language_translation}ï¼Œ"{text}"',
                },
                ],
                model=MODEL_NAME,
                temperature=0.95,
                top_p=0.7,
                stream=False,
                max_tokens=4095,
            )
            if response.choices:
                return response.choices[0].message.content.replace('"', '')
        return text
    

    def launch(self):
        with gr.Blocks(theme=gr.themes.Soft(), fill_height=True) as demo:
            gr.HTML(html_content)
            with gr.Row():
                with gr.Column():
                    with gr.Tabs():
                        with gr.TabItem("æœ¬åœ°ä¸Šä¼ "):
                            video_input = gr.File(
                                label="ä¸Šä¼ éŸ³è§†é¢‘æ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰", 
                                file_count="multiple",
                                file_types=["video","audio"],
                                type="filepath",
                            )
                        with gr.TabItem("URLè¾“å…¥"):
                            with gr.Column():
                                url_input = gr.Textbox(
                                    label="è§†é¢‘ç½‘å€",
                                    placeholder="æ”¯æŒå¤šä¸ªURLï¼Œç”¨æ¢è¡Œåˆ†éš”",
                                    lines=7,
                                    show_copy_button=True,
                                )       
                                gr.Markdown("ç‚¹å‡»æŸ¥çœ‹è‡ªåŠ¨ä¸‹è½½è§†é¢‘çš„[æ”¯æŒç½‘ç«™](https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md)")
                    with gr.Accordion(label="é…ç½®"):
                        model_inputs = gr.Dropdown(
                            label="æ¨¡å‹", 
                            choices=["æƒ…æ„Ÿæ¨¡å‹", "çƒ­è¯æ¨¡å‹", "æƒ…æ„Ÿæ¨¡å‹ï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰", "whisper-large-v3-turbo", "whisper-large-v3", "è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹"], 
                            value="è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹",
                        )
                        language_inputs = gr.Dropdown(
                            label="è¯†åˆ«è¯­è¨€", 
                            choices=["è‡ªåŠ¨", "ä¸­æ–‡", "è‹±æ–‡", "ç²¤è¯­", "æ—¥æ–‡", "éŸ©æ–‡", "æ— è¯­è¨€"], 
                            value="è‡ªåŠ¨",
                        )
                        language_translation = gr.Dropdown(
                            label="ç¿»è¯‘è¯­è¨€", 
                            choices=[
                                "ä¸ç¿»è¯‘", 
                                "ä¸­æ–‡", 
                                "è‹±è¯­", 
                                "è¥¿ç­ç‰™è¯­", 
                                "æ³•è¯­", "å¾·è¯­", "ä¿„è¯­", "æ—¥è¯­", "éŸ©è¯­", "é˜¿æ‹‰ä¼¯è¯­", "è‘¡è„ç‰™è¯­", "æ„å¤§åˆ©è¯­", "è·å…°è¯­", "ç‘å…¸è¯­", "æŒªå¨è¯­", "ä¸¹éº¦è¯­", "èŠ¬å…°è¯­", "å¸Œä¼¯æ¥è¯­", "å¸Œè…Šè¯­", "æ³°è¯­", "è¶Šå—è¯­", "å°å°¼è¯­", "é©¬æ¥è¯­", "æ³¢æ–¯è¯­", "å°åœ°è¯­", "ä¹Œå°”éƒ½è¯­", 
                            ],
                            value="ä¸ç¿»è¯‘",
                        )
                        format_selector = gr.Dropdown(
                            label="æ ¼å¼",
                            choices=["TXT", "LRC", "SRT"],
                            value="TXT",
                        )
                        hotwords_inputs = gr.Textbox(label="çƒ­è¯", value=self.hotwords)
                        speaker = gr.Checkbox(label="è¯†åˆ«è¯´è¯äººï¼ˆä»…çƒ­è¯æ¨¡å‹æ”¯æŒï¼‰", value=False)
                    fn_button = gr.Button("å¼€å§‹ç”Ÿæˆ", variant="primary")
                with gr.Column():
                    status_text = gr.Textbox(label="çŠ¶æ€", value="è¯·å…ˆé€‰æ‹©åŠ è½½æ¨¡å‹", interactive=False)
                    text_outputs = gr.Textbox(label="è¾“å‡º", show_copy_button=True)
                    download_file = gr.File(label="ä¸‹è½½æ–‡ä»¶", visible=False)  # æ–‡ä»¶ä¸‹è½½ç»„ä»¶

            model_inputs.change(
                self.load_model, 
                inputs=model_inputs, 
                outputs=[status_text, model_inputs]
            )
            fn_button.click(
                self.model_inference, 
                inputs=[
                    model_inputs,
                    video_input,
                    url_input,
                    language_inputs, 
                    language_translation,
                    hotwords_inputs,
                    format_selector,
                    speaker,
                ],
                outputs=[
                    status_text, 
                    text_outputs, 
                    download_file
                ],
                queue=True,
                show_progress=True
            )
        demo.launch(inbrowser=True, share=False, server_name="127.0.0.1")

html_content = """
    <div>
        <h2 style="font-size: 30px;text-align: center;">å…­è€³ Liuer</h2>
    </div>
    <div style="text-align: center;">
        åå­—é±¼
        <a href="https://space.bilibili.com/893892">ğŸŒbilibili</a> 
        |gluttony-10
        <a href="https://github.com/gluttony-10/Liuer">ğŸŒgithub</a> 
    </div>
    <div style="text-align: center; font-weight: bold; color: red;">
        âš ï¸ è¯¥æ¼”ç¤ºä»…ä¾›å­¦æœ¯ç ”ç©¶å’Œä½“éªŒä½¿ç”¨ã€‚
    </div>
"""

if __name__ == "__main__":
    print("å¼€æºé¡¹ç›®ï¼šhttps://github.com/gluttony-10/Liuer bilibili@åå­—é±¼ https://space.bilibili.com/893892 ")
    print(f'\033[32mPytorchç‰ˆæœ¬ï¼š{torch.__version__}\033[0m')
    if torch.cuda.is_available():
        print(f'\033[32mæ˜¾å¡å‹å·ï¼š{torch.cuda.get_device_name()}\033[0m')
        total_vram_in_gb = torch.cuda.get_device_properties(0).total_memory / 1073741824
        print(f'\033[32mæ˜¾å­˜å¤§å°ï¼š{total_vram_in_gb:.2f}GB\033[0m')
        if torch.cuda.get_device_capability()[0] >= 8:
            print(f'\033[32mæ”¯æŒBF16\033[0m')
            dtype = torch.bfloat16
        else:
            print(f'\033[32mä¸æ”¯æŒBF16ï¼Œä½¿ç”¨FP16\033[0m')
            dtype = torch.float16
    else:
        print(f'\033[32mCUDAä¸å¯ç”¨ï¼Œå¯ç”¨CPUuæ¨¡å¼\033[0m')
    app = FunASRApp()
    app.launch()